{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c426e006-1b6e-40e9-9e6c-7619b45b13c9",
   "metadata": {},
   "source": [
    "# Attention Transformer NN for King Heritage Data\n",
    "\n",
    "## Run 15\n",
    "\n",
    "`Test_30*` - `Test_31*`\n",
    "\n",
    "Sanity check training, where we are directly training a seq2seq model where input is same as Train_14, and output is one-hot encoded classes of which population/superpopulation the given indices fall into.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605e3fb-9fe6-4741-93b4-9097835e17be",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6d0319-88d9-4841-9ac9-db6e1f67b8e0",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T06:41:27.867765Z",
     "iopub.status.busy": "2024-11-26T06:41:27.867414Z",
     "iopub.status.idle": "2024-11-26T06:41:27.871962Z",
     "shell.execute_reply": "2024-11-26T06:41:27.870869Z",
     "shell.execute_reply.started": "2024-11-26T06:41:27.867735Z"
    },
    "gather": {
     "logged": 1722536559916
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#!conda activate jupyter_env\n",
    "#!pip install -r \"../requirements.txt\"\n",
    "# !pip install gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cf26f2f-02b7-4c6b-b2a8-8f6b7ac73c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T10:02:07.700508Z",
     "iopub.status.busy": "2024-12-06T10:02:07.700047Z",
     "iopub.status.idle": "2024-12-06T10:02:09.764383Z",
     "shell.execute_reply": "2024-12-06T10:02:09.763370Z",
     "shell.execute_reply.started": "2024-12-06T10:02:07.700484Z"
    },
    "gather": {
     "logged": 1723055177809
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## Import meta setup\n",
    "\n",
    "# In order to force reload any changes done to the models package files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Allow import from our custom lib python files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "# module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbc08f-25e6-4a1d-ad34-251aa798954b",
   "metadata": {},
   "source": [
    "### Fix for working in TLJH context\n",
    "\n",
    "Issue with multithreading spawning with the jupyter hub setup (The Littlest Jupyter Hub on Paperspace) and working with torch, and with the dataloader multithread loading. See the following for issue discussion and solution: \n",
    "\n",
    "https://github.com/pytorch/pytorch/issues/40403#issuecomment-1704178443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d0c594-fc79-481f-bc32-b403253b1f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:41:31.811937Z",
     "iopub.status.busy": "2024-11-26T06:41:31.811590Z",
     "iopub.status.idle": "2024-11-26T06:41:33.875808Z",
     "shell.execute_reply": "2024-11-26T06:41:33.875041Z",
     "shell.execute_reply.started": "2024-11-26T06:41:31.811912Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp \n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4b57708-51fd-4e48-9876-b88e6db99a32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T10:02:12.990570Z",
     "iopub.status.busy": "2024-12-06T10:02:12.990247Z",
     "iopub.status.idle": "2024-12-06T10:02:13.056118Z",
     "shell.execute_reply": "2024-12-06T10:02:13.055140Z",
     "shell.execute_reply.started": "2024-12-06T10:02:12.990547Z"
    },
    "gather": {
     "logged": 1723055198109
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "from lib.params import * # device, use_cuda, Checkpoint, various saving strs\n",
    "from lib.datasets import TokenizedPopDataset, TokenizedCollateFn\n",
    "from lib.models import TokenizedPopTransformer\n",
    "from lib.saveload import *\n",
    "from lib.training import train_model_tokenized, tokenized_masked_loss\n",
    "import lib.notebook_utils as custom_info\n",
    "\n",
    "import dill\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75144438",
   "metadata": {},
   "source": [
    "### Debug Machine Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fb97d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Python executable: /opt/tljh/user/bin/python\t3.10.10 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n",
      "Current Directory: /home/jupyter-bhavana/Notebooks\n",
      "==================== Imported Packages ====================\n",
      "sys==Python BuiltIn\n",
      "torch==2.1.0\n",
      "pandas==2.0.0\n",
      "numpy==1.24.4\n",
      "os==unknown\n",
      "json==unknown\n",
      "datetime==unknown\n",
      "lib==unknown\n",
      "======================================== System ========================================\n",
      "System: Linux\n",
      "Node Name: psapmaq8sxf1\n",
      "Release: 5.15.0-124-generic\n",
      "Version: #134-Ubuntu SMP Fri Sep 27 20:20:17 UTC 2024\n",
      "Machine: x86_64\n",
      "Processor: x86_64\n",
      "======================================== CPU ========================================\n",
      "Physical cores: 8\n",
      "Total cores: 8\n",
      "Max Frequency: 0.00Mhz\n",
      "Min Frequency: 0.00Mhz\n",
      "Current Frequency: 3202.58Mhz\n",
      "CPU Usage Per Core:\n",
      "Core 0: 0.0%\n",
      "Core 1: 0.0%\n",
      "Core 2: 0.0%\n",
      "Core 3: 0.0%\n",
      "Core 4: 0.0%\n",
      "Core 5: 0.0%\n",
      "Core 6: 0.0%\n",
      "Core 7: 0.0%\n",
      "Total CPU Usage: 0.7%\n",
      "======================================== Memory ========================================\n",
      "Total: 44.07GB\n",
      "Available: 42.53GB\n",
      "Used: 1.07GB\n",
      "Percentage: 3.5%\n",
      "==================== SWAP ====================\n",
      "Total: 0.00B\n",
      "Free: 0.00B\n",
      "Used: 0.00B\n",
      "Percentage: 0.0%\n",
      "======================================== Disk ========================================\n",
      "Partitions and Usage:\n",
      "=== Device: /dev/mapper/ubuntu--vg-root ===\n",
      "  Mountpoint: /\n",
      "  File system type: ext4\n",
      "  Total Size: 982.45GB\n",
      "  Used: 170.79GB\n",
      "  Free: 771.63GB\n",
      "  Percentage: 18.1%\n",
      "=== Device: /dev/loop0 ===\n",
      "  Mountpoint: /snap/core20/2318\n",
      "  File system type: squashfs\n",
      "  Total Size: 64.00MB\n",
      "  Used: 64.00MB\n",
      "  Free: 0.00B\n",
      "  Percentage: 100.0%\n",
      "=== Device: /dev/loop1 ===\n",
      "  Mountpoint: /snap/core20/2434\n",
      "  File system type: squashfs\n",
      "  Total Size: 63.75MB\n",
      "  Used: 63.75MB\n",
      "  Free: 0.00B\n",
      "  Percentage: 100.0%\n",
      "=== Device: /dev/loop2 ===\n",
      "  Mountpoint: /snap/lxd/24322\n",
      "  File system type: squashfs\n",
      "  Total Size: 112.00MB\n",
      "  Used: 112.00MB\n",
      "  Free: 0.00B\n",
      "  Percentage: 100.0%\n",
      "=== Device: /dev/loop3 ===\n",
      "  Mountpoint: /snap/lxd/29351\n",
      "  File system type: squashfs\n",
      "  Total Size: 87.12MB\n",
      "  Used: 87.12MB\n",
      "  Free: 0.00B\n",
      "  Percentage: 100.0%\n",
      "=== Device: /dev/loop4 ===\n",
      "  Mountpoint: /snap/snapd/17883\n",
      "  File system type: squashfs\n",
      "  Total Size: 49.62MB\n",
      "  Used: 49.62MB\n",
      "  Free: 0.00B\n",
      "  Percentage: 100.0%\n",
      "=== Device: /dev/loop5 ===\n",
      "  Mountpoint: /snap/snapd/21759\n",
      "  File system type: squashfs\n",
      "  Total Size: 38.88MB\n",
      "  Used: 38.88MB\n",
      "  Free: 0.00B\n",
      "  Percentage: 100.0%\n",
      "=== Device: /dev/xvda2 ===\n",
      "  Mountpoint: /boot\n",
      "  File system type: ext4\n",
      "  Total Size: 1.69GB\n",
      "  Used: 424.03MB\n",
      "  Free: 1.17GB\n",
      "  Percentage: 26.2%\n",
      "Total read: 1.48GB\n",
      "Total write: 129.08MB\n",
      "======================================== Network ========================================\n",
      "=== Interface: lo ===\n",
      "  IP Address: 127.0.0.1\n",
      "  Netmask: 255.0.0.0\n",
      "  Broadcast IP: None\n",
      "=== Interface: lo ===\n",
      "=== Interface: lo ===\n",
      "  MAC Address: 00:00:00:00:00:00\n",
      "  Netmask: None\n",
      "  Broadcast MAC: None\n",
      "=== Interface: eth0 ===\n",
      "  IP Address: 10.64.9.55\n",
      "  Netmask: 255.255.240.0\n",
      "  Broadcast IP: 10.64.15.255\n",
      "=== Interface: eth0 ===\n",
      "=== Interface: eth0 ===\n",
      "  MAC Address: 32:68:cb:4c:c9:16\n",
      "  Netmask: None\n",
      "  Broadcast MAC: ff:ff:ff:ff:ff:ff\n",
      "Total Bytes Sent: 19.28MB\n",
      "Total Bytes Received: 12.21MB\n",
      "======================================== GPU ========================================\n",
      "  id  name              load    free memory    used memory    total memory    temperature    uuid\n",
      "----  ----------------  ------  -------------  -------------  --------------  -------------  ----------------------------------------\n",
      "   0  NVIDIA RTX A6000  0.0%    48672.0MB      3.0MB          49140.0MB       40.0 °C        GPU-648300e5-e89d-c8d6-4ceb-1a4b88574b1f\n"
     ]
    }
   ],
   "source": [
    "custom_info.print_python_info()\n",
    "custom_info.print_imports(globals())\n",
    "custom_info.print_machine_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480465ba-0bae-40f4-b9cb-cc7c05db14c0",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a54ff7-0a8e-4794-883a-18df67ab452e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T05:48:08.047092Z",
     "iopub.status.busy": "2024-12-06T05:48:08.045167Z",
     "iopub.status.idle": "2024-12-06T05:48:08.110345Z",
     "shell.execute_reply": "2024-12-06T05:48:08.109499Z",
     "shell.execute_reply.started": "2024-12-06T05:48:08.047057Z"
    },
    "gather": {
     "logged": 1723055216785
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "runname = \"test15\"\n",
    "machine = \"Paperspace\"\n",
    "datapath = \"../Data/king_matrix.csv\"\n",
    "outdir = os.path.join(\"../Output/Runs/\", runname)\n",
    "tensorboard_dir = \"../Output/Tensorboard\"\n",
    "SEED = 42\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "if not os.path.exists(tensorboard_dir):\n",
    "    os.mkdir(tensorboard_dir)\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f9495-6e07-4030-a22f-598f212ed9fe",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d9808c9-9b1d-4394-bdd4-0f116c7caef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T05:54:04.891975Z",
     "iopub.status.busy": "2024-12-06T05:54:04.891064Z",
     "iopub.status.idle": "2024-12-06T05:54:05.002275Z",
     "shell.execute_reply": "2024-12-06T05:54:05.001314Z",
     "shell.execute_reply.started": "2024-12-06T05:54:04.891946Z"
    }
   },
   "outputs": [],
   "source": [
    "# The official 1000 genome sample names to popcodes\n",
    "sample_to_popcode = pd.read_csv(\"../Data/igsr_samples.tsv\", sep=\"\\t\")[[\"Sample name\", \"Population code\", \"Superpopulation code\", \"Superpopulation name\"]].dropna()\n",
    "pop_to_superpop = sample_to_popcode.set_index(\"Population code\").to_dict()[\"Superpopulation code\"]\n",
    "\n",
    "# Label int to popcode\n",
    "king_popcodes = pd.read_csv(\"../Output/Heritage_UMAP/variable_to_integer_conversion_tribe_string_labels.csv\", index_col=0)\n",
    "\n",
    "# Labels as ints\n",
    "y_ints = pd.read_csv(\"../Output/Heritage_UMAP/labels_file_series.csv\", index_col=0)[\"0\"]\n",
    "# Labels as popcodes\n",
    "y_codes = y_ints.replace(king_popcodes.set_index(\"0\").to_dict()[\"1\"])\n",
    "y_super_codes = y_codes.replace(pop_to_superpop)\n",
    "y_super_ints = y_super_codes.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04af740b-96ff-486c-bdc6-caad82e053ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T10:02:16.261997Z",
     "iopub.status.busy": "2024-12-06T10:02:16.261626Z",
     "iopub.status.idle": "2024-12-06T10:02:50.107818Z",
     "shell.execute_reply": "2024-12-06T10:02:50.106552Z",
     "shell.execute_reply.started": "2024-12-06T10:02:16.261967Z"
    },
    "gather": {
     "logged": 1723055389380
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 3 torch.Size([2]) torch.Size([2])\n",
      "16000 2 torch.Size([28]) (tensor([ 147, 1457,  367,  751, 1486, 2499, 1700,  762, 2068, 1403,  584,   50,\n",
      "        1216, 1031,  567, 1279,  594,  195, 1650, 2437, 1154,   73,  485, 2071,\n",
      "        1787, 1873, 1546,  611], dtype=torch.int32), tensor([3, 4, 1, 2, 4, 4, 3, 0, 0, 4, 3, 3, 0, 0, 3, 0, 3, 2, 4, 4, 0, 3, 1, 0,\n",
      "        2, 2, 4, 3]))\n",
      "(tensor([[ 553, 1026, 2128,  ..., 2503, 2503, 2503],\n",
      "        [1757, 1500, 1345,  ..., 2503, 2503, 2503],\n",
      "        [1667, 1454, 1957,  ..., 2503, 2503, 2503],\n",
      "        ...,\n",
      "        [1501,  875,    7,  ..., 2503, 2503, 2503],\n",
      "        [ 329, 2294, 1875,  ..., 2503, 2503, 2503],\n",
      "        [1905, 2022, 1817,  ..., 2503, 2503, 2503]], dtype=torch.int32), tensor([[3, 4, 0,  ..., 5, 5, 5],\n",
      "        [0, 4, 0,  ..., 5, 5, 5],\n",
      "        [3, 4, 2,  ..., 5, 5, 5],\n",
      "        ...,\n",
      "        [4, 1, 3,  ..., 5, 5, 5],\n",
      "        [1, 3, 2,  ..., 5, 5, 5],\n",
      "        [0, 2, 2,  ..., 5, 5, 5]]), tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]))\n"
     ]
    }
   ],
   "source": [
    "dsize = 20000\n",
    "vstart = int(dsize * 0.8)\n",
    "maxseqlen = 100\n",
    "maxind = 2502\n",
    "# padval = -1\n",
    "batchsize = 50\n",
    "\n",
    "dataset = TokenizedPopDataset(datapath, y_ints, dsize=dsize, maxseqlen=maxseqlen, maxind=maxind)\n",
    "dataset_superpop = TokenizedPopDataset(datapath, y_super_ints, dsize=dsize, maxseqlen=maxseqlen, maxind=maxind)\n",
    "\n",
    "# Don't need to random sample to make subsets since they're already random lens of random inds, and want even distribution\n",
    "# of representative indices in both train/test\n",
    "train, test = Subset(dataset, range(vstart)), Subset(dataset, range(vstart, dsize))\n",
    "train_superpop, test_superpop = Subset(dataset_superpop, range(vstart)), Subset(dataset_superpop, range(vstart, dsize))\n",
    "\n",
    "dl_args = dict(batch_size=batchsize, shuffle=True, num_workers=6)\n",
    "fn=TokenizedCollateFn(dataset.padind, dataset.padval).collate_fn\n",
    "fn_superpop=TokenizedCollateFn(dataset_superpop.padind, dataset_superpop.padval).collate_fn\n",
    "train_dataloader, test_dataloader = DataLoader(train, **dl_args, collate_fn=fn), DataLoader(test, **dl_args, collate_fn=fn)\n",
    "train_superpop_dataloader, test_superpop_dataloader = DataLoader(train_superpop, **dl_args, collate_fn=fn_superpop)\\\n",
    "                                                        ,DataLoader(test_superpop, **dl_args, collate_fn=fn_superpop)\n",
    "\n",
    "\n",
    "print(len(dataset), len(dataset[-1][0]), dataset[0][0].shape, dataset[0][1].shape)\n",
    "print(len(train_superpop), len(train_superpop[0][0]), train_superpop[2501][0].shape, train_superpop[2501])\n",
    "print(next(iter(test_superpop_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da448e-a25d-4852-9f91-8aaf3e8eaa76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T16:13:54.125685Z",
     "iopub.status.busy": "2024-07-05T16:13:54.125029Z",
     "iopub.status.idle": "2024-07-05T16:13:54.166989Z",
     "shell.execute_reply": "2024-07-05T16:13:54.166041Z",
     "shell.execute_reply.started": "2024-07-05T16:13:54.125656Z"
    }
   },
   "source": [
    "## Create Model(s)\n",
    "\n",
    "30. Train on pop labels\n",
    "31. Train on superpop labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dac57af-177f-4ff9-b301-ed4b1654f109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T09:47:00.860432Z",
     "iopub.status.busy": "2024-12-06T09:47:00.860030Z",
     "iopub.status.idle": "2024-12-06T09:47:00.991838Z",
     "shell.execute_reply": "2024-12-06T09:47:00.990663Z",
     "shell.execute_reply.started": "2024-12-06T09:47:00.860402Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TokenizedPopTransformer(\n",
      "  (pos_encoding): Identity()\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=120, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=120, bias=True)\n",
      "        (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=120, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=120, bias=True)\n",
      "        (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed): Embedding(2504, 120, padding_idx=2503)\n",
      "  (outshape): Linear(in_features=120, out_features=26, bias=True)\n",
      "), TokenizedPopTransformer(\n",
      "  (pos_encoding): Identity()\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=120, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=120, bias=True)\n",
      "        (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=120, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=120, bias=True)\n",
      "        (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed): Embedding(2504, 120, padding_idx=2503)\n",
      "  (outshape): Linear(in_features=120, out_features=5, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# Using random amt a bit greater than maxseqlen; and d_model = embed_size\n",
    "d_model = 120\n",
    "\n",
    "model_names = [\"Test_30_pop_2h\", \"Test_31_superpop_2h\"]\n",
    "base_params = dict(d_model=d_model,\n",
    "                    num_encoder_layers=3,\n",
    "                    num_decoder_layers=2,\n",
    "                    dim_feedforward=512,\n",
    "                    activation=nn.Tanh(),\n",
    "                    use_pe=False,\n",
    "                    dropout_pe=0.0,\n",
    "                    maxseqlen=maxseqlen, \n",
    "                    maxind=maxind,\n",
    "                   num_head=2\n",
    "                  )\n",
    "\n",
    "run_details = {\"run_params\": dict(\n",
    "                    machine=machine,\n",
    "                    epochs = 80,\n",
    "                    checkpoint_at = 20,\n",
    "                    load=False,\n",
    "                    batch_pr=int(dsize / batchsize / 5), # Print/validate every 1/5 of epoch\n",
    "                    runname=runname\n",
    "                    ),\n",
    "                model_names[0]: dict(\n",
    "                    name=model_names[0],\n",
    "                    num_classes=y_ints.max() + 1\n",
    "                    ) | base_params,\n",
    "                model_names[1]: dict(\n",
    "                    name=model_names[1],\n",
    "                    num_classes=y_super_ints.max() + 1\n",
    "                    ) | base_params,\n",
    "                }\n",
    "models = [TokenizedPopTransformer(**run_details[m]).to(device) for m in model_names]\n",
    "\n",
    "assert models[1].padind == dataset_superpop.padind\n",
    "\n",
    "print(models)\n",
    "\n",
    "# Save details\n",
    "with open(os.path.join(outdir, f\"details_{runname}.json\"), \"w\" ) as write:\n",
    "    json.dump(run_details, write, indent=2, default=lambda x: f\"nn.{x.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4478fd-aaa8-4fb9-a30c-1d28a4991d5e",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1561b9e0-e90e-4f37-a748-32a69f34565c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T09:47:03.189095Z",
     "iopub.status.busy": "2024-12-06T09:47:03.188524Z",
     "iopub.status.idle": "2024-12-06T09:47:31.887346Z",
     "shell.execute_reply": "2024-12-06T09:47:31.886129Z",
     "shell.execute_reply.started": "2024-12-06T09:47:03.189012Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 26, 98]) tensor([[[ 4.9694e-01,  8.9748e-01, -3.9411e-01,  ..., -3.4695e-01,\n",
      "          -1.2233e-01, -9.7160e-02],\n",
      "         [ 3.0515e-01,  3.4287e-01, -6.6585e-01,  ...,  1.4235e-01,\n",
      "           3.1590e-06,  3.3469e-01],\n",
      "         [ 8.4043e-01,  4.5042e-01,  7.8379e-01,  ..., -3.6689e-01,\n",
      "          -2.9166e-01,  8.2611e-02],\n",
      "         ...,\n",
      "         [-1.2249e+00,  3.9670e-01, -3.5684e-01,  ..., -2.9317e-01,\n",
      "          -8.7460e-01, -6.2133e-01],\n",
      "         [-7.5833e-01, -9.0963e-01, -7.5382e-01,  ...,  1.3078e-01,\n",
      "          -2.0079e-01,  6.4995e-02],\n",
      "         [-1.0702e-01, -5.0885e-01, -5.0882e-01,  ...,  3.9217e-01,\n",
      "           7.0239e-01,  7.3099e-01]],\n",
      "\n",
      "        [[-2.2034e-01,  1.3193e-01, -7.5610e-02,  ..., -8.9451e-01,\n",
      "          -6.1028e-01, -7.8862e-01],\n",
      "         [-3.1998e-01,  5.5012e-02,  3.2584e-01,  ...,  7.3531e-01,\n",
      "           7.8946e-01,  1.0029e+00],\n",
      "         [ 1.9118e-02,  6.1852e-01,  2.9956e-01,  ...,  6.3022e-01,\n",
      "           2.9075e-01,  8.2590e-01],\n",
      "         ...,\n",
      "         [ 3.2373e-01,  4.4519e-01,  7.0217e-02,  ..., -5.8044e-01,\n",
      "          -7.6795e-01, -6.0579e-01],\n",
      "         [-1.8402e-01, -9.6617e-02, -3.0613e-01,  ...,  7.6474e-01,\n",
      "           1.1244e+00,  1.3198e+00],\n",
      "         [-6.9409e-01, -1.1085e+00, -2.4043e-01,  ..., -2.0155e-01,\n",
      "          -3.3307e-01, -2.1385e-01]],\n",
      "\n",
      "        [[-6.5451e-01, -1.7144e-01,  3.6724e-02,  ..., -1.6005e-01,\n",
      "          -4.4691e-01, -6.7999e-01],\n",
      "         [-6.9895e-01, -5.1671e-01,  6.8636e-02,  ..., -4.3992e-01,\n",
      "           5.6155e-02, -9.2873e-02],\n",
      "         [ 1.5001e-01,  1.9449e-01,  8.2170e-01,  ...,  1.0795e+00,\n",
      "           5.0417e-01,  9.1864e-01],\n",
      "         ...,\n",
      "         [ 6.5658e-01, -7.5300e-02, -1.5177e+00,  ..., -5.2169e-01,\n",
      "          -8.7149e-01, -6.8819e-01],\n",
      "         [ 1.0303e-01, -7.9274e-01, -5.9807e-01,  ..., -1.1667e+00,\n",
      "          -1.2066e+00, -8.9538e-01],\n",
      "         [ 7.5312e-02, -2.7347e-01,  1.2413e+00,  ...,  9.8734e-02,\n",
      "          -1.7239e-01, -9.9082e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7197e-01, -3.8622e-02,  6.1497e-01,  ..., -7.6006e-01,\n",
      "          -3.9672e-01, -6.4439e-01],\n",
      "         [ 1.0123e-01,  2.9147e-01,  9.3720e-01,  ..., -8.0402e-01,\n",
      "          -6.1103e-01, -4.9962e-01],\n",
      "         [-1.5009e-01,  3.8099e-01, -5.9477e-01,  ...,  3.1305e-01,\n",
      "           4.6796e-02,  7.1281e-02],\n",
      "         ...,\n",
      "         [ 2.2195e-01, -9.9031e-02, -1.3205e-01,  ...,  1.8459e-01,\n",
      "          -8.6857e-02,  9.5519e-02],\n",
      "         [-2.6238e-01, -3.8360e-01, -8.4191e-01,  ..., -2.7556e-01,\n",
      "          -5.2858e-03,  1.9606e-02],\n",
      "         [-5.7304e-01,  3.6838e-01,  2.5156e-01,  ...,  2.0605e-01,\n",
      "           2.1759e-01, -1.9015e-01]],\n",
      "\n",
      "        [[ 1.1484e+00, -2.7161e-01,  1.4431e+00,  ..., -1.3506e-01,\n",
      "           1.8192e-01,  2.3478e-01],\n",
      "         [ 1.9327e-01,  1.3621e+00, -6.9377e-01,  ..., -1.1294e+00,\n",
      "          -6.7631e-01, -6.7502e-01],\n",
      "         [-7.3755e-01,  1.0643e+00, -2.8610e-01,  ...,  2.9431e-01,\n",
      "           5.3294e-01,  7.5036e-01],\n",
      "         ...,\n",
      "         [-3.9727e-02, -1.0608e-01, -8.8281e-01,  ...,  2.3504e-01,\n",
      "           4.7963e-01,  9.4625e-01],\n",
      "         [ 1.0751e-02, -9.4579e-01, -2.6177e-01,  ...,  2.7601e-01,\n",
      "           6.8877e-01,  2.9375e-02],\n",
      "         [ 4.2845e-02,  1.2915e-01, -6.1844e-02,  ...,  4.8685e-01,\n",
      "          -3.3321e-01,  3.6687e-01]],\n",
      "\n",
      "        [[ 4.9536e-01,  3.5156e-01,  4.8208e-01,  ..., -4.6041e-01,\n",
      "          -2.9193e-01, -5.1966e-01],\n",
      "         [ 4.6692e-01,  4.2476e-01,  4.4762e-01,  ..., -3.2266e-02,\n",
      "          -1.5688e-01, -1.8565e-01],\n",
      "         [-5.5457e-01,  7.0571e-01,  3.2702e-01,  ...,  4.9460e-01,\n",
      "           5.1766e-01,  5.1410e-01],\n",
      "         ...,\n",
      "         [ 2.0852e-02,  7.5917e-01, -1.0574e-01,  ...,  1.0483e+00,\n",
      "           7.5739e-01,  5.4196e-01],\n",
      "         [ 5.2026e-02, -3.5278e-01,  3.2410e-02,  ..., -9.7218e-02,\n",
      "          -4.4035e-02, -5.1999e-01],\n",
      "         [ 1.7180e-01, -6.3717e-01, -5.0283e-01,  ..., -5.6021e-01,\n",
      "          -8.4312e-01, -7.5030e-01]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# tstdata = next(iter(train_superpop_dataloader))\n",
    "# f = models[0](tstdata[0], tstdata[2])\n",
    "# print(f.shape, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88784850-d7ec-4cc8-bf32-af288e03b966",
   "metadata": {},
   "source": [
    "## Train the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "760e2659-92f6-4921-893f-80090f91b240",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T10:03:05.668502Z",
     "iopub.status.busy": "2024-12-06T10:03:05.668114Z",
     "iopub.status.idle": "2024-12-06T10:13:32.551211Z",
     "shell.execute_reply": "2024-12-06T10:13:32.549173Z",
     "shell.execute_reply.started": "2024-12-06T10:03:05.668473Z"
    },
    "gather": {
     "logged": 1723055543098
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Test_30_pop_2h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjonnalagadda/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 80] loss: 3.2303109407424926, validation loss: 3.0945286095142364, average train time (sec): 0.014232998700754252\n",
      "[0, 160] loss: 2.947646087408066, validation loss: 2.756226372718811, average train time (sec): 0.0104105636375607\n",
      "[0, 240] loss: 2.603339359164238, validation loss: 2.387198027968407, average train time (sec): 0.006780774737126194\n",
      "[0, 320] loss: 2.2214962035417556, validation loss: 1.9376036271452903, average train time (sec): 0.0073950860125478355\n",
      "[1, 80] loss: 1.72471232265234, validation loss: 1.2814940422773362, average train time (sec): 0.00881681335013127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Set foreach=False to avoid OOM\u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, foreach\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain_model_tokenized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_fcn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fcn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# No padval used with loss fn\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_run_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_onnx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     25\u001b[0m loss_fcn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mdataset_superpop\u001b[38;5;241m.\u001b[39mpadval)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UCB-O365/Work/Ecotone/Internship2024/src/lib/training.py:99\u001b[0m, in \u001b[0;36mtrain_model_tokenized\u001b[0;34m(model, optimizer, train_data, validate_data, output_run_dir, machine, loss_fcn, padval, epochs, checkpoint_at, load, batch_pr, writer, output_onnx, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fcn(out_seq, data_y, padval)\n\u001b[1;32m     98\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 99\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m running_time \u001b[38;5;241m=\u001b[39m default_timer() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    102\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "loss_fcn = nn.CrossEntropyLoss(ignore_index=dataset.padval)\n",
    "model = models[0]\n",
    "\n",
    "writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))\n",
    "# Set foreach=False to avoid OOM\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, foreach=False)\n",
    "\n",
    "train_model_tokenized(model=model,\n",
    "            optimizer=optimizer,\n",
    "            train_data=train_dataloader,\n",
    "            validate_data=test_dataloader,\n",
    "            loss_fcn=loss_fcn,\n",
    "            padval=None, # No padval used with loss fn\n",
    "            output_run_dir=outdir,\n",
    "            **run_details[\"run_params\"],\n",
    "            writer=writer,\n",
    "            output_onnx=False\n",
    "        )\n",
    "\n",
    "\n",
    "writer.close()\n",
    "\n",
    "\n",
    "loss_fcn = nn.CrossEntropyLoss(ignore_index=dataset_superpop.padval)\n",
    "model = models[1]\n",
    "\n",
    "writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))\n",
    "# Set foreach=False to avoid OOM\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, foreach=False)\n",
    "\n",
    "train_model_tokenized(model=model,\n",
    "            optimizer=optimizer,\n",
    "            train_data=train_superpop_dataloader,\n",
    "            validate_data=test_superpop_dataloader,\n",
    "            loss_fcn=loss_fcn,\n",
    "            padval=None, # No padval used with loss fn\n",
    "            output_run_dir=outdir,\n",
    "            **run_details[\"run_params\"],\n",
    "            writer=writer,\n",
    "            output_onnx=False\n",
    "        )\n",
    "\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6ae33-e865-4c26-8e88-40881ec2d57a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
